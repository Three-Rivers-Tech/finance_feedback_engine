<ml_examples>
  <overview>
    Complete end-to-end examples of ML workflows in the Finance Feedback Engine,
    demonstrating best practices and common patterns.
  </overview>

  <example name="building_lstm_price_predictor">
    <description>
      Build an LSTM model to predict next-day price movements and integrate
      with the decision engine.
    </description>

    <workflow>
      <step number="1">
        <title>Research existing implementations</title>
        <actions>
          <action>
            <tool>codebase_search</tool>
            <query>LSTM time series neural network prediction</query>
          </action>
          <action>
            <tool>read_file</tool>
            <files>
              <file>finance_feedback_engine/data_providers/unified_data_provider.py</file>
              <file>finance_feedback_engine/decision_engine/engine.py</file>
            </files>
          </action>
        </actions>
      </step>

      <step number="2">
        <title>Create model architecture</title>
        <code><![CDATA[
# File: examples/lstm_price_predictor.py

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

class LSTMPricePredictor(nn.Module):
    """LSTM model for next-day price prediction."""

    def __init__(self, input_size=10, hidden_size=128, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,
                           batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])

def prepare_data(df, sequence_length=20):
    """Prepare sequences for LSTM training."""
    features = ['close', 'volume', 'rsi_14', 'macd', 'atr_14']

    # Create sequences
    X, y = [], []
    for i in range(sequence_length, len(df)):
        X.append(df[features].iloc[i-sequence_length:i].values)
        y.append(df['close'].iloc[i])

    return np.array(X), np.array(y)

def train_model(asset_pair='BTCUSD', epochs=100):
    """Train LSTM model on historical data."""
    # Load data
    from finance_feedback_engine.data_providers import AlphaVantageProvider
    provider = AlphaVantageProvider()
    df = provider.get_daily_data(asset_pair, outputsize='full')

    # Prepare sequences
    X, y = prepare_data(df)

    # Train/test split (chronological)
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    # Create model
    model = LSTMPricePredictor(input_size=X.shape[2])
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # Training loop
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()

        X_tensor = torch.FloatTensor(X_train)
        y_tensor = torch.FloatTensor(y_train).unsqueeze(1)

        outputs = model(X_tensor)
        loss = criterion(outputs, y_tensor)
        loss.backward()
        optimizer.step()

        if epoch % 10 == 0:
            model.eval()
            with torch.no_grad():
                val_outputs = model(torch.FloatTensor(X_test))
                val_loss = criterion(val_outputs,
                                   torch.FloatTensor(y_test).unsqueeze(1))
            print(f"Epoch {epoch}: Train Loss={loss:.4f}, Val Loss={val_loss:.4f}")

    # Save model
    torch.save(model.state_dict(), 'models/lstm_btc_predictor.pt')
    return model

if __name__ == '__main__':
    model = train_model()
        ]]></code>
      </step>

      <step number="3">
        <title>Create AI provider integration</title>
        <code><![CDATA[
# File: finance_feedback_engine/decision_engine/lstm_provider.py

import torch
from typing import Dict, Any, Optional
import logging

from .lstm_price_predictor import LSTMPricePredictor

logger = logging.getLogger(__name__)

class LSTMProvider:
    """AI provider using LSTM for price predictions."""

    def __init__(self, model_path='models/lstm_btc_predictor.pt'):
        self.model = LSTMPricePredictor()
        self.model.load_state_dict(torch.load(model_path))
        self.model.eval()

    def query(self, prompt_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Generate trading decision from LSTM prediction."""
        try:
            # Extract features from prompt
            features = self._extract_features(prompt_data)

            # Make prediction
            with torch.no_grad():
                prediction = self.model(features)

            current_price = prompt_data.get('current_price', 0)
            predicted_price = prediction.item()

            # Calculate expected return
            expected_return = (predicted_price - current_price) / current_price

            # Determine action
            if expected_return > 0.02:  # 2% threshold
                action = "BUY"
                confidence = min(expected_return * 10, 1.0)
            elif expected_return < -0.02:
                action = "SELL"
                confidence = min(abs(expected_return) * 10, 1.0)
            else:
                action = "HOLD"
                confidence = 0.7

            return {
                "action": action,
                "confidence": confidence,
                "reasoning": f"LSTM predicts price of ${predicted_price:.2f} "
                           f"(current: ${current_price:.2f}, "
                           f"expected return: {expected_return*100:.2f}%)",
                "metadata": {
                    "provider": "lstm",
                    "predicted_price": predicted_price,
                    "expected_return": expected_return
                }
            }
        except Exception as e:
            logger.error(f"LSTM provider failed: {e}")
            return None

    def _extract_features(self, prompt_data: Dict[str, Any]):
        """Extract and format features for LSTM."""
        # Implementation depends on prompt structure
        pass
        ]]></code>
      </step>

      <step number="4">
        <title>Integrate with ensemble manager</title>
        <instructions>
          Use apply_diff to add LSTM provider to ensemble_manager.py:
          - Add import statement
          - Add to provider initialization
          - Configure weight in config.yaml
        </instructions>
      </step>

      <step number="5">
        <title>Backtest the model</title>
        <command>python main.py backtest BTCUSD --provider lstm --start 2024-01-01</command>
      </step>
    </workflow>
  </example>

  <example name="xgboost_signal_classifier">
    <description>
      Train XGBoost model to classify buy/sell/hold signals based on
      technical indicators.
    </description>

    <workflow>
      <step number="1">
        <title>Feature engineering script</title>
        <code><![CDATA[
# File: examples/train_xgboost_classifier.py

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import classification_report
import joblib

def create_features(df):
    """Create comprehensive feature set."""
    features = pd.DataFrame(index=df.index)

    # Returns at multiple horizons
    for period in [1, 5, 10, 20]:
        features[f'return_{period}d'] = df['close'].pct_change(period)

    # Technical indicators
    features['rsi_14'] = calculate_rsi(df['close'], 14)
    features['macd'] = calculate_macd(df['close'])
    features['bb_position'] = calculate_bb_position(df['close'])
    features['atr_14'] = calculate_atr(df, 14)
    features['adx_14'] = calculate_adx(df, 14)

    # Volume features
    features['volume_ratio'] = df['volume'] / df['volume'].rolling(20).mean()
    features['volume_trend'] = df['volume'].pct_change(5)

    # Price action
    features['high_low_ratio'] = df['high'] / df['low']
    features['close_position'] = (df['close'] - df['low']) / (df['high'] - df['low'])

    return features.dropna()

def create_labels(df, threshold=0.02):
    """Create labels: 0=SELL, 1=HOLD, 2=BUY."""
    future_return = df['close'].shift(-1) / df['close'] - 1
    labels = pd.Series(1, index=df.index)  # Default HOLD
    labels[future_return > threshold] = 2   # BUY
    labels[future_return < -threshold] = 0  # SELL
    return labels[:-1]

def train_xgboost(asset_pair='BTCUSD'):
    """Train XGBoost classifier."""
    # Load data
    from finance_feedback_engine.data_providers import AlphaVantageProvider
    provider = AlphaVantageProvider()
    df = provider.get_daily_data(asset_pair, outputsize='full')

    # Prepare features and labels
    X = create_features(df)
    y = create_labels(df)

    # Align
    min_len = min(len(X), len(y))
    X, y = X.iloc[:min_len], y.iloc[:min_len]

    # Time series cross-validation
    tscv = TimeSeriesSplit(n_splits=5)
    best_model = None
    best_score = 0

    for train_idx, val_idx in tscv.split(X):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        model = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.1,
            objective='multi:softmax',
            num_class=3
        )

        model.fit(X_train, y_train,
                 eval_set=[(X_val, y_val)],
                 early_stopping_rounds=20,
                 verbose=False)

        score = model.score(X_val, y_val)
        if score > best_score:
            best_score = score
            best_model = model

    print(f"Best validation score: {best_score:.4f}")

    # Final evaluation
    split_idx = int(len(X) * 0.8)
    X_test, y_test = X.iloc[split_idx:], y.iloc[split_idx:]
    y_pred = best_model.predict(X_test)

    print("\nTest Set Performance:")
    print(classification_report(y_test, y_pred,
                               target_names=['SELL', 'HOLD', 'BUY']))

    # Save model
    joblib.dump(best_model, 'models/xgboost_classifier.pkl')
    return best_model

if __name__ == '__main__':
    train_xgboost()
        ]]></code>
      </step>

      <step number="2">
        <title>Run training</title>
        <command>python examples/train_xgboost_classifier.py</command>
      </step>

      <step number="3">
        <title>Validate with walk-forward analysis</title>
        <command>python main.py walk-forward BTCUSD --provider xgboost --train-ratio 0.7</command>
      </step>
    </workflow>
  </example>

  <example name="ensemble_stacking">
    <description>
      Create stacked ensemble combining LSTM, XGBoost, and traditional indicators.
    </description>

    <workflow>
      <step number="1">
        <title>Configure ensemble in config.yaml</title>
        <code><![CDATA[
decision_engine:
  ai_provider: "ensemble"
  ensemble_config:
    providers:
      - name: "lstm"
        weight: 0.3
        enabled: true
      - name: "xgboost"
        weight: 0.3
        enabled: true
      - name: "local"
        weight: 0.2
        enabled: true
      - name: "cli"
        weight: 0.2
        enabled: true

    voting_strategy: "weighted"
    quorum_threshold: 3
    confidence_threshold: 0.6
        ]]></code>
      </step>

      <step number="2">
        <title>Test ensemble</title>
        <command>python main.py analyze BTCUSD --provider ensemble</command>
      </step>

      <step number="3">
        <title>Compare ensemble vs individual models</title>
        <code><![CDATA[
# Script: examples/compare_ensemble.py

import pandas as pd
from finance_feedback_engine import FinanceFeedbackEngine

def compare_providers(asset_pair='BTCUSD'):
    """Compare individual providers vs ensemble."""
    engine = FinanceFeedbackEngine()

    providers = ['lstm', 'xgboost', 'local', 'ensemble']
    results = {}

    for provider in providers:
        decision = engine.analyze_asset(asset_pair, provider=provider)
        results[provider] = {
            'action': decision['action'],
            'confidence': decision['confidence'],
            'reasoning': decision['reasoning']
        }

    df = pd.DataFrame(results).T
    print(df)

    return df

if __name__ == '__main__':
    compare_providers()
        ]]></code>
      </step>
    </workflow>
  </example>

  <example name="reinforcement_learning_agent">
    <description>
      Train RL agent to learn optimal trading policy.
    </description>

    <workflow>
      <step number="1">
        <title>Create trading environment</title>
        <note>See 3_model_patterns.xml for complete TradingEnvironment implementation</note>
      </step>

      <step number="2">
        <title>Train PPO agent</title>
        <code><![CDATA[
# File: examples/train_rl_agent.py

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from trading_environment import TradingEnvironment

def train_rl_agent():
    """Train RL agent using PPO."""
    # Load market data
    from finance_feedback_engine.data_providers import AlphaVantageProvider
    provider = AlphaVantageProvider()
    df = provider.get_daily_data('BTCUSD', outputsize='full')

    # Create environment
    env = DummyVecEnv([lambda: TradingEnvironment(df)])

    # Create model
    model = PPO(
        'MlpPolicy',
        env,
        learning_rate=0.0003,
        n_steps=2048,
        batch_size=64,
        verbose=1
    )

    # Train
    model.learn(total_timesteps=100000)
    model.save('models/ppo_trading_agent')

    return model

if __name__ == '__main__':
    train_rl_agent()
        ]]></code>
      </step>

      <step number="3">
        <title>Evaluate agent</title>
        <command>python examples/evaluate_rl_agent.py</command>
      </step>

      <step number="4">
        <title>Deploy with autonomous agent</title>
        <command>python main.py run-agent --provider rl_agent --trading-platform mock</command>
      </step>
    </workflow>
  </example>

  <example name="model_monitoring_and_retraining">
    <description>
      Set up continuous monitoring and automated retraining pipeline.
    </description>

    <workflow>
      <step number="1">
        <title>Monitor prediction accuracy</title>
        <code><![CDATA[
# File: examples/monitor_model_performance.py

import pandas as pd
from finance_feedback_engine.monitoring import TradeMonitor
from finance_feedback_engine.memory import PortfolioMemoryEngine

def monitor_ml_predictions():
    """Track ML model predictions vs actual outcomes."""
    monitor = TradeMonitor()
    memory = PortfolioMemoryEngine()

    # Get completed trades
    trades = memory.get_all_trades()

    # Calculate accuracy
    correct_predictions = 0
    total_predictions = 0

    for trade in trades:
        if 'ml_prediction' in trade:
            predicted_direction = trade['ml_prediction']['action']
            actual_pnl = trade['pnl']

            predicted_correct = (
                (predicted_direction == 'BUY' and actual_pnl > 0) or
                (predicted_direction == 'SELL' and actual_pnl < 0) or
                (predicted_direction == 'HOLD' and abs(actual_pnl) < 0.01)
            )

            if predicted_correct:
                correct_predictions += 1
            total_predictions += 1

    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
    print(f"ML Model Accuracy: {accuracy:.2%}")

    # Check if retraining needed
    if accuracy < 0.55:  # Below threshold
        print("Warning: Model accuracy below threshold. Consider retraining.")
        trigger_retraining()

    return accuracy

def trigger_retraining():
    """Trigger automated model retraining."""
    print("Initiating model retraining pipeline...")
    # Implementation of retraining logic

if __name__ == '__main__':
    monitor_ml_predictions()
        ]]></code>
      </step>

      <step number="2">
        <title>Detect concept drift</title>
        <code><![CDATA[
from scipy import stats

def detect_drift(recent_predictions, historical_predictions):
    """Detect distribution shift using KS test."""
    statistic, pvalue = stats.ks_2samp(recent_predictions, historical_predictions)

    if pvalue < 0.05:
        print(f"Drift detected! KS statistic: {statistic:.4f}, p-value: {pvalue:.4f}")
        return True
    return False
        ]]></code>
      </step>

      <step number="3">
        <title>Automated retraining script</title>
        <code><![CDATA[
# File: scripts/retrain_models.py

import schedule
import time

def retrain_all_models():
    """Retrain all ML models with latest data."""
    models = ['lstm', 'xgboost', 'rl_agent']

    for model in models:
        print(f"Retraining {model}...")
        # Call appropriate training script

def schedule_retraining():
    """Schedule weekly model retraining."""
    schedule.every().sunday.at("02:00").do(retrain_all_models)

    while True:
        schedule.run_pending()
        time.sleep(3600)  # Check every hour

if __name__ == '__main__':
    schedule_retraining()
        ]]></code>
      </step>
    </workflow>
  </example>

  <integration_examples>
    <example name="add_ml_to_existing_system">
      <description>Step-by-step integration of ML models into existing system</description>
      <steps>
        <step>Search for ensemble manager: codebase_search "ensemble manager"</step>
        <step>Read ensemble_manager.py and understand provider structure</step>
        <step>Create ML provider class following existing patterns</step>
        <step>Add provider to ensemble configuration</step>
        <step>Set initial low weight (10%) for safety</step>
        <step>Test in shadow mode (log predictions without trading)</step>
        <step>Validate performance over 1-2 weeks</step>
        <step>Gradually increase weight if performance good</step>
      </steps>
    </example>

    <example name="ab_test_models">
      <description>A/B test new ML model against baseline</description>
      <code><![CDATA[
# Compare two models over same period
python main.py backtest BTCUSD --provider baseline --start 2024-01-01 --end 2024-02-01
python main.py backtest BTCUSD --provider new_ml_model --start 2024-01-01 --end 2024-02-01

# Compare metrics: Sharpe ratio, max drawdown, win rate
      ]]></code>
    </example>
  </integration_examples>
</ml_examples>
